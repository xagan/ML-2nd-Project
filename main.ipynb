{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-04-26T07:50:02.664207300Z",
     "start_time": "2024-04-26T07:50:02.659208500Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "import numpy as np\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import SelectKBest, chi2, mutual_info_classif\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Open the original CSV file and create a new CSV file for corrected data\n",
    "with open('data.csv', 'r') as original_file, open('corrected.csv', 'w', newline='') as corrected_file:\n",
    "    # Create a CSV reader and writer objects\n",
    "    reader = csv.reader(original_file, delimiter=';')\n",
    "    writer = csv.writer(corrected_file)\n",
    "    \n",
    "    # Read the header and write it to the new CSV file\n",
    "    header = next(reader)\n",
    "    writer.writerow(header)\n",
    "    \n",
    "    # Iterate over each row in the original CSV\n",
    "    for row in reader:\n",
    "        # Split the single column into multiple columns\n",
    "        # Write the split data into the new CSV file\n",
    "        writer.writerow(row)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-26T07:50:03.255245600Z",
     "start_time": "2024-04-26T07:50:03.217246200Z"
    }
   },
   "id": "fba545cd23e61e80",
   "execution_count": 38
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv('corrected.csv')\n",
    "df.head()\n",
    "\n",
    "# Preprocess the data\n",
    "X = df.drop(['Curricular units 1st sem (grade)', 'Curricular units 2nd sem (grade)'], axis=1)  # features\n",
    "y = df['GDP']  # target variable (dropout)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-26T07:50:03.786304100Z",
     "start_time": "2024-04-26T07:50:03.753413800Z"
    }
   },
   "id": "e39e4af3e89ec920",
   "execution_count": 39
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected a 2-dimensional container but got <class 'pandas.core.series.Series'> instead. Pass a DataFrame containing a single row (i.e. single sample) or a single column (i.e. single feature) instead.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[40], line 3\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m# Label Encoding\u001B[39;00m\n\u001B[0;32m      2\u001B[0m label_encoder \u001B[38;5;241m=\u001B[39m OneHotEncoder()\n\u001B[1;32m----> 3\u001B[0m y_encoded \u001B[38;5;241m=\u001B[39m \u001B[43mlabel_encoder\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit_transform\u001B[49m\u001B[43m(\u001B[49m\u001B[43my\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      5\u001B[0m \u001B[38;5;66;03m# One-Hot Encoding (if there are more than two classes)\u001B[39;00m\n\u001B[0;32m      6\u001B[0m \u001B[38;5;66;03m# If there are only two classes, Label Encoding is sufficient\u001B[39;00m\n\u001B[0;32m      7\u001B[0m y_encoded \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mget_dummies(y)\n",
      "File \u001B[1;32mF:\\Uni\\ML-2nd-Project\\.venv\\lib\\site-packages\\sklearn\\utils\\_set_output.py:295\u001B[0m, in \u001B[0;36m_wrap_method_output.<locals>.wrapped\u001B[1;34m(self, X, *args, **kwargs)\u001B[0m\n\u001B[0;32m    293\u001B[0m \u001B[38;5;129m@wraps\u001B[39m(f)\n\u001B[0;32m    294\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mwrapped\u001B[39m(\u001B[38;5;28mself\u001B[39m, X, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m--> 295\u001B[0m     data_to_wrap \u001B[38;5;241m=\u001B[39m f(\u001B[38;5;28mself\u001B[39m, X, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    296\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(data_to_wrap, \u001B[38;5;28mtuple\u001B[39m):\n\u001B[0;32m    297\u001B[0m         \u001B[38;5;66;03m# only wrap the first output for cross decomposition\u001B[39;00m\n\u001B[0;32m    298\u001B[0m         return_tuple \u001B[38;5;241m=\u001B[39m (\n\u001B[0;32m    299\u001B[0m             _wrap_data_with_container(method, data_to_wrap[\u001B[38;5;241m0\u001B[39m], X, \u001B[38;5;28mself\u001B[39m),\n\u001B[0;32m    300\u001B[0m             \u001B[38;5;241m*\u001B[39mdata_to_wrap[\u001B[38;5;241m1\u001B[39m:],\n\u001B[0;32m    301\u001B[0m         )\n",
      "File \u001B[1;32mF:\\Uni\\ML-2nd-Project\\.venv\\lib\\site-packages\\sklearn\\base.py:1098\u001B[0m, in \u001B[0;36mTransformerMixin.fit_transform\u001B[1;34m(self, X, y, **fit_params)\u001B[0m\n\u001B[0;32m   1083\u001B[0m         warnings\u001B[38;5;241m.\u001B[39mwarn(\n\u001B[0;32m   1084\u001B[0m             (\n\u001B[0;32m   1085\u001B[0m                 \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mThis object (\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m) has a `transform`\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1093\u001B[0m             \u001B[38;5;167;01mUserWarning\u001B[39;00m,\n\u001B[0;32m   1094\u001B[0m         )\n\u001B[0;32m   1096\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m y \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m   1097\u001B[0m     \u001B[38;5;66;03m# fit method of arity 1 (unsupervised transformation)\u001B[39;00m\n\u001B[1;32m-> 1098\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfit(X, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mfit_params)\u001B[38;5;241m.\u001B[39mtransform(X)\n\u001B[0;32m   1099\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   1100\u001B[0m     \u001B[38;5;66;03m# fit method of arity 2 (supervised transformation)\u001B[39;00m\n\u001B[0;32m   1101\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfit(X, y, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mfit_params)\u001B[38;5;241m.\u001B[39mtransform(X)\n",
      "File \u001B[1;32mF:\\Uni\\ML-2nd-Project\\.venv\\lib\\site-packages\\sklearn\\base.py:1474\u001B[0m, in \u001B[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001B[1;34m(estimator, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1467\u001B[0m     estimator\u001B[38;5;241m.\u001B[39m_validate_params()\n\u001B[0;32m   1469\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m config_context(\n\u001B[0;32m   1470\u001B[0m     skip_parameter_validation\u001B[38;5;241m=\u001B[39m(\n\u001B[0;32m   1471\u001B[0m         prefer_skip_nested_validation \u001B[38;5;129;01mor\u001B[39;00m global_skip_validation\n\u001B[0;32m   1472\u001B[0m     )\n\u001B[0;32m   1473\u001B[0m ):\n\u001B[1;32m-> 1474\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m fit_method(estimator, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32mF:\\Uni\\ML-2nd-Project\\.venv\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:975\u001B[0m, in \u001B[0;36mOneHotEncoder.fit\u001B[1;34m(self, X, y)\u001B[0m\n\u001B[0;32m    956\u001B[0m \u001B[38;5;129m@_fit_context\u001B[39m(prefer_skip_nested_validation\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[0;32m    957\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mfit\u001B[39m(\u001B[38;5;28mself\u001B[39m, X, y\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[0;32m    958\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    959\u001B[0m \u001B[38;5;124;03m    Fit OneHotEncoder to X.\u001B[39;00m\n\u001B[0;32m    960\u001B[0m \n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    973\u001B[0m \u001B[38;5;124;03m        Fitted encoder.\u001B[39;00m\n\u001B[0;32m    974\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m--> 975\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_fit\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    976\u001B[0m \u001B[43m        \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    977\u001B[0m \u001B[43m        \u001B[49m\u001B[43mhandle_unknown\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mhandle_unknown\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    978\u001B[0m \u001B[43m        \u001B[49m\u001B[43mforce_all_finite\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mallow-nan\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m    979\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    980\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_set_drop_idx()\n\u001B[0;32m    981\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_n_features_outs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compute_n_features_outs()\n",
      "File \u001B[1;32mF:\\Uni\\ML-2nd-Project\\.venv\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:78\u001B[0m, in \u001B[0;36m_BaseEncoder._fit\u001B[1;34m(self, X, handle_unknown, force_all_finite, return_counts, return_and_ignore_missing_for_infrequent)\u001B[0m\n\u001B[0;32m     76\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_check_n_features(X, reset\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[0;32m     77\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_check_feature_names(X, reset\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[1;32m---> 78\u001B[0m X_list, n_samples, n_features \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_check_X\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m     79\u001B[0m \u001B[43m    \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mforce_all_finite\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mforce_all_finite\u001B[49m\n\u001B[0;32m     80\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     81\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_features_in_ \u001B[38;5;241m=\u001B[39m n_features\n\u001B[0;32m     83\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcategories \u001B[38;5;241m!=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mauto\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n",
      "File \u001B[1;32mF:\\Uni\\ML-2nd-Project\\.venv\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:44\u001B[0m, in \u001B[0;36m_BaseEncoder._check_X\u001B[1;34m(self, X, force_all_finite)\u001B[0m\n\u001B[0;32m     31\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m     32\u001B[0m \u001B[38;5;124;03mPerform custom check_array:\u001B[39;00m\n\u001B[0;32m     33\u001B[0m \u001B[38;5;124;03m- convert list of strings to object dtype\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     40\u001B[0m \n\u001B[0;32m     41\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m     42\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mhasattr\u001B[39m(X, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124miloc\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mgetattr\u001B[39m(X, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mndim\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;241m0\u001B[39m) \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m2\u001B[39m):\n\u001B[0;32m     43\u001B[0m     \u001B[38;5;66;03m# if not a dataframe, do normal check_array validation\u001B[39;00m\n\u001B[1;32m---> 44\u001B[0m     X_temp \u001B[38;5;241m=\u001B[39m \u001B[43mcheck_array\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mforce_all_finite\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mforce_all_finite\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     45\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(X, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdtype\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;129;01mand\u001B[39;00m np\u001B[38;5;241m.\u001B[39missubdtype(X_temp\u001B[38;5;241m.\u001B[39mdtype, np\u001B[38;5;241m.\u001B[39mstr_):\n\u001B[0;32m     46\u001B[0m         X \u001B[38;5;241m=\u001B[39m check_array(X, dtype\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mobject\u001B[39m, force_all_finite\u001B[38;5;241m=\u001B[39mforce_all_finite)\n",
      "File \u001B[1;32mF:\\Uni\\ML-2nd-Project\\.venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1035\u001B[0m, in \u001B[0;36mcheck_array\u001B[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001B[0m\n\u001B[0;32m   1028\u001B[0m         \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   1029\u001B[0m             msg \u001B[38;5;241m=\u001B[39m (\n\u001B[0;32m   1030\u001B[0m                 \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mExpected 2D array, got 1D array instead:\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124marray=\u001B[39m\u001B[38;5;132;01m{\u001B[39;00marray\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   1031\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mReshape your data either using array.reshape(-1, 1) if \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   1032\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124myour data has a single feature or array.reshape(1, -1) \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   1033\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mif it contains a single sample.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   1034\u001B[0m             )\n\u001B[1;32m-> 1035\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(msg)\n\u001B[0;32m   1037\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m dtype_numeric \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(array\u001B[38;5;241m.\u001B[39mdtype, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mkind\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;129;01mand\u001B[39;00m array\u001B[38;5;241m.\u001B[39mdtype\u001B[38;5;241m.\u001B[39mkind \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mUSV\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[0;32m   1038\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m   1039\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdtype=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mnumeric\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m is not compatible with arrays of bytes/strings.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   1040\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mConvert your data to numeric values explicitly instead.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   1041\u001B[0m     )\n",
      "\u001B[1;31mValueError\u001B[0m: Expected a 2-dimensional container but got <class 'pandas.core.series.Series'> instead. Pass a DataFrame containing a single row (i.e. single sample) or a single column (i.e. single feature) instead."
     ]
    }
   ],
   "source": [
    "# Label Encoding\n",
    "label_encoder = OneHotEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "# One-Hot Encoding (if there are more than two classes)\n",
    "# If there are only two classes, Label Encoding is sufficient\n",
    "y_encoded = pd.get_dummies(y)\n",
    "\n",
    "\n",
    "# Handle class imbalance using SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "X_res, y_res = smote.fit_resample(X, y_encoded)\n",
    "\n",
    "# X_res, y_res = smote.fit_resample(X, y)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_res, y_res, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize the data\n",
    "scaler = StandardScaler()\n",
    "X_train_std = scaler.fit_transform(X_train)\n",
    "X_test_std = scaler.transform(X_test)\n",
    "\n",
    "# Feature Selection using SelectKBest\n",
    "k = 10  # select top 10 features\n",
    "selector = SelectKBest(mutual_info_classif, k=k)\n",
    "X_train_selected = selector.fit_transform(X_train_std, y_train)\n",
    "X_test_selected = selector.transform(X_test_std)\n",
    "\n",
    "# Feature Extraction using PCA\n",
    "pca = PCA(n_components=0.95)  # retain 95% of the variance\n",
    "X_train_pca = pca.fit_transform(X_train_std)\n",
    "X_test_pca = pca.transform(X_test_std)\n",
    "\n",
    "# Feature Extraction using t-SNE\n",
    "tsne = TSNE(n_components=2, random_state=42)\n",
    "X_train_tsne = tsne.fit_transform(X_train_std)\n",
    "X_test_tsne = tsne.transform(X_test_std)\n",
    "\n",
    "# Train a random forest classifier on the original data\n",
    "rfc = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rfc.fit(X_train_std, y_train)\n",
    "y_pred_rfc = rfc.predict(X_test_std)\n",
    "print(\"Original Data:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_rfc))\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_rfc))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_rfc))\n",
    "\n",
    "# Train a random forest classifier on the selected features\n",
    "rfc_selected = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rfc_selected.fit(X_train_selected, y_train)\n",
    "y_pred_rfc_selected = rfc_selected.predict(X_test_selected)\n",
    "print(\"Selected Features:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_rfc_selected))\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_rfc_selected))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_rfc_selected))\n",
    "\n",
    "# Train a random forest classifier on the PCA features\n",
    "rfc_pca = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rfc_pca.fit(X_train_pca, y_train)\n",
    "y_pred_rfc_pca = rfc_pca.predict(X_test_pca)\n",
    "print(\"PCA Features:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_rfc_pca))\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_rfc_pca))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_rfc_pca))\n",
    "\n",
    "# Train a random forest classifier on the t-SNE features\n",
    "rfc_tsne = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rfc_tsne.fit(X_train_tsne, y_train)\n",
    "y_pred_rfc_tsne = rfc_tsne.predict(X_test_tsne)\n",
    "print(\"t-SNE Features:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_rfc_tsne))\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_rfc_tsne))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_rfc_tsne))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-26T07:50:04.867355100Z",
     "start_time": "2024-04-26T07:50:04.578983200Z"
    }
   },
   "id": "f750ba76a19d98c8",
   "execution_count": 40
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "59972b208aefd446"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
